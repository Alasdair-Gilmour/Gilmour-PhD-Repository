{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39c1d1-739e-4e61-b8ac-c495b4958400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import skimage.filters\n",
    "import scipy.ndimage\n",
    "import pandas as pd\n",
    "import skimage.transform\n",
    "import more_itertools as mit\n",
    "import math\n",
    "import os\n",
    "\n",
    "###################\n",
    "# pot_scan_to_pkl #\n",
    "###################\n",
    "# A function to convert scanned pages into a pkl file of separate Image Arrays\n",
    "\n",
    "# Parameters:\n",
    "#              input_page = .png or .tiff file to be processed\n",
    "#               threshold = Value from 0-255, all pixels < the value go to 0, all pixels >= the value go to\n",
    "#                           255. If value is not specified it will be automatically determined using Otsu\n",
    "#                           thresholding. Manual input of threshold only reccommended if Otsu threshold \n",
    "#                           doesn't provide satisfactory results.\n",
    "#   diagonal_pixel_groups = If False, only horizontally and vertically connected pixels form labels,\n",
    "#                           if True, horizontally, vertically, and diagonally connected pixels can.\n",
    "#         viable_pot_size = The minimum number of pixels required for a label to be recognised as a\n",
    "#                           potential pot. By default it is 2000, though this may need to be raised or\n",
    "#                           lowered manually depending on the nature of the input image.\n",
    "#              output_pkl = If True, output df is converted to a .pkl file and saved,\n",
    "#                           If False, output is temporarily stored as func_output_df\n",
    "#                   nomen = If nomen is given, this is used to name the output, otherwise based on input page filename\n",
    "\n",
    "\n",
    "def pot_scan_to_pkl(input_page, threshold=None, diagonal_pixel_groups=True, viable_pot_size=4000, output_pkl=False, nomen=None):\n",
    "    \n",
    "    # Opens the input image, converts it to 8bit greyscale, inverts the colours,\n",
    "    # adds a border and converts to a numpy array\n",
    "    \n",
    "    scanned_page = Image.open(input_page)\n",
    "    scanned_page = scanned_page.convert('L')\n",
    "    scanned_page = ImageOps.invert(scanned_page)\n",
    "    scanned_page = ImageOps.expand(scanned_page, border=10, fill='black')\n",
    "    scanned_page = np.array(scanned_page)\n",
    "    \n",
    "    # If a threshold has been provided, all pixels >= are turned to white, all\n",
    "    # pixels < are turned to black. If threshold is not provided, one is automatically\n",
    "    # produced through Otsu threshold filtering and applied similarly to produce\n",
    "    # a binary image.\n",
    "    \n",
    "    if threshold:\n",
    "        scanned_page[scanned_page >= threshold] = 255\n",
    "        scanned_page[scanned_page <  threshold] = 0\n",
    "    else:\n",
    "        otsu_value = skimage.filters.threshold_otsu(scanned_page)\n",
    "        scanned_page[scanned_page >= otsu_value] = 255\n",
    "        scanned_page[scanned_page <  otsu_value] = 0\n",
    "        print ('otsu_threshold =', otsu_value)\n",
    "    \n",
    "    # Creates a structure to allow or disallow diagonally adjacent pixel groups to form\n",
    "    # labels in the next function.\n",
    "    \n",
    "    if diagonal_pixel_groups is True:\n",
    "        s = [[255,255,255],\n",
    "             [255,255,255],\n",
    "             [255,255,255]]\n",
    "    elif diagonal_pixel_groups is False:\n",
    "        s = [[0,  255,0  ],\n",
    "             [255,255,255],\n",
    "             [0,  255,0  ]]\n",
    "    \n",
    "    # Creates a labelled array whereby each individual group of adjacent non-zero pixels\n",
    "    # is allocated a distinct individual integer, then creates a list of tuples detailing\n",
    "    # the integer assigned to each label, and the number of pixels that make up each label.\n",
    "    \n",
    "    labelled_array, num_features = scipy.ndimage.measurements.label(scanned_page, structure=s)\n",
    "    unique_labels, pixels_per_label = np.unique(labelled_array, return_counts=True)                                         \n",
    "    unique_labels = tuple(unique_labels)\n",
    "    pixels_per_label = tuple(pixels_per_label)\n",
    "    labels_with_pixels = list(zip(unique_labels,pixels_per_label))\n",
    "    \n",
    "    # Iterates over the list of labels to see if any are associated with enough pixels\n",
    "    # (as determined by the viable_pot_size variable) to be possible pots. Smaller labels\n",
    "    # tend to be things like individual letters of text or page numbers. Any sufficiently\n",
    "    # large labels are then appended to a the possible_pots list. The function then prints\n",
    "    # the number of pots that have been found to make sure this matches expectations.\n",
    "    \n",
    "    possible_pots = []\n",
    "    for (x,y) in labels_with_pixels:\n",
    "        if y>=viable_pot_size:                  \n",
    "            possible_pots.append(x)\n",
    "    \n",
    "    print (\"Pots found =\", len(possible_pots)-1)\n",
    "    \n",
    "    # Creates a reference image of the scanned page with everything but the possible pot\n",
    "    # labels removed by iterating over the possible_pots list and removing any labels that\n",
    "    # don't feature on it. This image can then be used to help manually identify the image\n",
    "    # outputs on the basis of shape, surviving decoration, artefacts of scanning etc. and\n",
    "    # to ensure that all the pots have been properly scanned. (the Path function grabs the filename from the file location)\n",
    "    \n",
    "    reference_image = labelled_array\n",
    "    for x in possible_pots:\n",
    "        if x > 0:\n",
    "            reference_image = np.where(reference_image == x, 255, reference_image)\n",
    "    reference_image[reference_image > 255] = 0\n",
    "    reference_image[reference_image < 255] = 0\n",
    "    reference_image = Image.fromarray(reference_image)\n",
    "    reference_image = reference_image.convert('L')\n",
    "    \n",
    "    if nomen is None:\n",
    "        nomen = Path(input_page).stem\n",
    "    reference_image.save('reference_image_%s.png' % nomen)\n",
    "    \n",
    "    # Creates an empty output list, then iterates over all the possible non-zero pot labels.\n",
    "    # For each label, the function turns other labels to 0, crops around the remaining\n",
    "    # non-zero pixels, turns all remaining non-zero pixels to 255 (hopefully leaving just\n",
    "    # the pot) then appends the array to the output list.\n",
    "    \n",
    "    output_pots = []\n",
    "    for x in possible_pots:\n",
    "        if x > 0:\n",
    "            pot = np.where(labelled_array == x, x, 0)\n",
    "            pot = pot[np.ix_(pot.any(1),pot.any(0))]\n",
    "            pot[pot > 0] = 255\n",
    "            output_pots.append(pot)\n",
    "    \n",
    "    # Converts the output_pots list to a dataframe, then saves as a .pkl file with the\n",
    "    # Same name as the input file. Scans with only a single pot seem to need the output\n",
    "    # pots list to be more nested, I'm not entirely sure why. Also prints an error\n",
    "    # statement if < 1 pot is found\n",
    "    \n",
    "    if len(output_pots) > 1:\n",
    "        pot_data_frame = pd.DataFrame(output_pots, columns = ['Image Array'])\n",
    "    elif len(output_pots) == 1:\n",
    "        pot_data_frame = pd.DataFrame([output_pots], columns = ['Image Array'])\n",
    "    else:\n",
    "        print (\"SOMETHING HAS CLEARLY GONE WRONG - LESS THAN ONE POT FOUND\")\n",
    "        \n",
    "    # If an output pkl is needed, one is produced, otherwise the data is temporarily stored as an output df\n",
    "        \n",
    "    if output_pkl is True:\n",
    "        pot_data_frame.to_pickle('%s.pkl' % filename)\n",
    "    return pot_data_frame\n",
    "\n",
    "\n",
    "\n",
    "######################    \n",
    "# new_autorotate_all #\n",
    "######################\n",
    "# A function to automatically rotate pots to an upright position, or 90/180 degrees from an upright position.\n",
    "# It may be advisable to run this function several times, starting with a broad degree range and high degree\n",
    "# increment, then lowering both values once a more accurate range has been established\n",
    "#\n",
    "#\n",
    "# This new version takes into account cases with thick centre lines where there\n",
    "# might be multiple rotations that offer a max col value by reiterating over the\n",
    "# values, rather than just selecting the first one.\n",
    "#\n",
    "# NOTE - At some point you should do something vaguely statistical to figure out a senhsible minmum degree\n",
    "#        increment - difference seems to be fairly minimal once you go beyond 1/8th of a degree\n",
    "#\n",
    "# Parameters:\n",
    "#         input_data = A data frame or .pkl file with the images requiring rotation stored in the 'Image Array' column\n",
    "#       degree_range = An integer value determining the max degrees either side of 0, 90 and -90 that will\n",
    "#                      be trialled during autorotation. For very lopsided images consider expanding beyond\n",
    "#                      10, but this is not usually necessary\n",
    "#   degree_increment = The number of degrees the image is rotated by in each attempt. It is advisable to keep\n",
    "#                      this value as 1/(2^n) to avoid rounding errors:\n",
    "#                         1/8 : 0.125\n",
    "#                        1/16 : 0.0625\n",
    "#                        1/32 : 0.03125\n",
    "#                        1/64 : 0.015625\n",
    "#                       1/128 : 0.0078125\n",
    "#                       1/256 : 0.00390625\n",
    "#                       1/512 : 0.001953125\n",
    "#                      1/1024 : 0.0009765625\n",
    "# ignore_horizontals = If True, only vertical lines are checked for straightness\n",
    "#         output_pkl = If True, output df is converted to a .pkl file and saved,\n",
    "#                      If False, output is temporarily stored as func_output_df\n",
    "#              nomen = If nomen is given, this is used to name the output, otherwise ..............\n",
    "\n",
    "def new_autorotate_all(input_data, degree_range=10,degree_increment=1/8, ignore_horizontals=False, output_pkl=False, nomen=None):\n",
    "    \n",
    "    # Reads the .pkl file as a data frame if necessary, creates a list of indices and an\n",
    "    # empty rotated pot list to fill with outputs. Also creates a list of\n",
    "    # degrees to try rotating the images too based on the function parameters.\n",
    "    # This list of degrees always comprises of those up to the degree range\n",
    "    # clockwise and counterclockwise of the current orientation, and if ignore\n",
    "    # horizontals is set to false, it includes increments around a 90 degree rotation\n",
    "    # as well (so that long vessels can be righted by using the top horizontal line).\n",
    "    # Inculding horiztonal lines can however be problematic for wonky vessels.\n",
    "\n",
    "    if type(input_data) == str:\n",
    "        data_frame = pd.read_pickle(input_pickle)\n",
    "    elif isinstance(input_data,pd.DataFrame):\n",
    "        data_frame = input_data\n",
    "    index_list = list(data_frame.index.values)\n",
    "    rotated_pot_list =[]\n",
    "    \n",
    "    bot_degree_list = np.arange(-90, -90+degree_range+degree_increment, degree_increment).tolist()\n",
    "    mid_degree_list = np.arange(-degree_range, degree_range+degree_increment, degree_increment).tolist()\n",
    "    top_degree_list = np.arange(90-degree_range, 90+degree_increment, degree_increment).tolist()\n",
    "    \n",
    "    if ignore_horizontals == False:\n",
    "        degree_list = bot_degree_list+mid_degree_list+top_degree_list\n",
    "        \n",
    "    elif ignore_horizontals == True:\n",
    "        degree_list = mid_degree_list\n",
    "    \n",
    "    # For each image array (obtained through iterating over the data frame using the index list), \n",
    "    # iterates over the list of degrees, each time rotating the original pot image by the degree\n",
    "    # under consideration (rotating the original image rather than repeating rotation avoids\n",
    "    # distortion) then for each rotation records the sum of all the values for each column, takes\n",
    "    # the largest sum, and appends it to the value_list.\n",
    "    #\n",
    "    # The logic here is that we are finding the rotation that gives us the straightest vertical line. This will\n",
    "    # usually be either the vertical line separating the two halves of the typological image, or the straight line\n",
    "    # running horizontally along the top of a shorter, wider vessel like a plate or a lid. So making this line as\n",
    "    # straight as possible will usually result in an image of a pot that is upright, upside down, or on its side\n",
    "    # In the latter two cases the pot can then be manually rotated by a multiple of 90 degrees to achieve uprightness.\n",
    "    \n",
    "    for x in index_list:\n",
    "        pot_array = data_frame.at[x, 'Image Array']\n",
    "        value_list = []\n",
    "        for y in degree_list:\n",
    "            temp_pot = skimage.transform.rotate(pot_array, angle=y, resize=True, center=None, preserve_range=True, order=0)\n",
    "            temp_columns = temp_pot.sum(axis=0)\n",
    "            temp_columns = sorted(temp_columns, reverse=True)\n",
    "            temp_column_max = max(temp_columns)\n",
    "            value_list.append(temp_column_max)\n",
    "            \n",
    "        # Creates a smaller degree list, containing only those rotations that result in the highest value (straightest)\n",
    "        # vertical line.\n",
    "\n",
    "        rotation_indices = ([pos for pos, val in enumerate(value_list) if val == max(value_list)])\n",
    "        short_degree_list = []\n",
    "        for i in rotation_indices:\n",
    "            short_degree_list.append(degree_list[i])\n",
    "        \n",
    "        # If there is only one rotation that produces the highest value vertical line, the function continues. If multiple rotations\n",
    "        # however are able to produce the same max value (usually becuase the centre line is thick enough that it can still be slightly\n",
    "        # wonky but still be giving a similarly hiugh value to a perfectly straight line), then more processing is needed. This while\n",
    "        # statement iterates over the list of rotation degrees that produce the max value, then records the top 2 column values for that\n",
    "        # rotation and sums them (the logic being that a n pixel thick central line would have multiple high value columns, whereas a\n",
    "        # wonky one may just have one or two). Only the rotations with the highest 2 column sum are preserved. If there is now only one\n",
    "        # rotation left, it is taken forward, otherwise the process repeats taking the highests 3,4,5...n highest column values until\n",
    "        # only one rotation remains\n",
    "        \n",
    "        counter = 0\n",
    "        while len(short_degree_list) > 1:\n",
    "            new_value_list = []\n",
    "            for d in short_degree_list:\n",
    "                temp_pot = skimage.transform.rotate(pot_array, angle=d, resize=True, center=None, preserve_range=True, order=0)\n",
    "                temp_columns = temp_pot.sum(axis=0)\n",
    "                temp_columns = sorted(temp_columns, reverse=True)\n",
    "                new_temp_column_max = temp_columns[:counter+1]\n",
    "                new_temp_column_max = sum(new_temp_column_max)\n",
    "                new_value_list.append(new_temp_column_max)\n",
    "            rotation_indices = ([pos for pos, val in enumerate(new_value_list) if val == max(new_value_list)])\n",
    "            new_short_degree_list = []\n",
    "            for i in rotation_indices:\n",
    "                new_short_degree_list.append(short_degree_list[i])\n",
    "            short_degree_list = new_short_degree_list\n",
    "            counter += 1\n",
    "            \n",
    "            # This is here to stop an infinite loop happening - if this seems to be happening, it just takes the middle value from the list\n",
    "            \n",
    "            if counter > 19:\n",
    "                short_degree_list = [short_degree_list[int(len(short_degree_list)/2)]]\n",
    "        \n",
    "        # Rotates the original image by the degree determined to be optimal above\n",
    "        \n",
    "        desired_rotation = short_degree_list[0]\n",
    "        rotated_pot = skimage.transform.rotate(pot_array, angle=desired_rotation, resize=True, center=None, preserve_range=True, order=0)\n",
    "        \n",
    "        # If the image has been rotated by close to 90 degrees clockwise or anticlockwise (usually as a result of a line\n",
    "        # along the top of a vessel being longer than the one down the middle), it is rotated by an increment of 90 degrees\n",
    "        # to reorient it to being upright\n",
    "        \n",
    "        based_on_centre_line = True\n",
    "        if desired_rotation > 80:\n",
    "            rotated_pot = skimage.transform.rotate(rotated_pot, angle=-90, resize=True, center=None, preserve_range=True, order=0)\n",
    "            desired_rotation -= 90\n",
    "            based_on_centre_line = False\n",
    "        if desired_rotation < -80:\n",
    "            rotated_pot = skimage.transform.rotate(rotated_pot, angle=90, resize=True, center=None, preserve_range=True, order=0)\n",
    "            desired_rotation += 90\n",
    "            based_on_centre_line = False\n",
    "        \n",
    "        # The array is trimmed to remove excess black space, and appended to the output list. Print \n",
    "        # statements show progress and the extent to which the arrays have been rotated. If all the\n",
    "        # values are within a small range, it may be worth reusing this function on the original data\n",
    "        # with a tighter degree_range and smaller degree_increment for more accurate outputs\n",
    "        \n",
    "        rotated_pot = rotated_pot[np.ix_(rotated_pot.any(1),rotated_pot.any(0))]\n",
    "        rotated_pot_list.append(rotated_pot)\n",
    "        print ('Pot_%s rotated by %s degrees' % (x, -desired_rotation), '(Centre line = %s,' % (based_on_centre_line), '%s additional iterations)' % (counter))\n",
    "        \n",
    "    # After all the images are rotated, the original image arrays in the data frame\n",
    "    # are replaced with the rotated versions and the data frame is saved as a .pkl file or func_output_df\n",
    "    # Because the input might not have name data attached, unique pkl output is impossible without provided names\n",
    "    \n",
    "    data_frame['Image Array'] = rotated_pot_list\n",
    "    if output_pkl is True:\n",
    "        if nomen is None:\n",
    "            print (\"NO .pkl PRODUCED - NOMEN REQUIRED FOR .pkl OUTPUT\")\n",
    "        else:\n",
    "            data_frame.to_pickle('rotated_%s.pkl' % nomen)\n",
    "    return data_frame\n",
    "\n",
    "##########################\n",
    "# mirror_and_trim_centre #\n",
    "##########################\n",
    "# A function to take fully rotated pot image arrays where the left hand side of the image is a cross-section,\n",
    "# and the right hand side depicts exterior details, and output a complete cross-section based on the left hand\n",
    "# side by mirroring it and erasing the central vertical line of the image. Outputs may still contain extraneous\n",
    "# horizontal lines and details which will need to be dealt with later. It is probably best to manually identify\n",
    "# pots prior to applying this function, as it erases much of the detail that helps with identification.\n",
    "\n",
    "# Parameters:\n",
    "#        input_pickle : A data frame with the arrays requiring processing stored in the 'Image Array' column\n",
    "# centre_slice_pixels : The width in pixels of the rightmost slice of the image to be removed, processed and replaced \n",
    "#                       to remove the centre line. For narrow top/bottomed vessels, this value may need to be smaller\n",
    "#  centre_line_pixels : The number of pixels each row of the centre_line_slice needs to exceed in order for that row \n",
    "#                       not to be turned to black. Images with thick or irregular central lines may need higher values.\n",
    "#                       This Value should not exceed the centre_line_pixels value\n",
    "\n",
    "def mirror_and_trim_centre_all(input_data, centre_slice_pixels=10, centre_line_pixels=4, output_pkl=False, nomen=None):\n",
    "    \n",
    "    # Reads the data frame from the input .pkl file and creates an empty list for outputs,\n",
    "    # then iterates through each image array to carry out the rest of the function.\n",
    "    # If Designations are present, these are used for the later print progress statements, \n",
    "    # otherwise generic index based designations are generated and used.\n",
    "    \n",
    "    if type(input_data) == str:\n",
    "        data_frame = pd.read_pickle(input_pickle)\n",
    "    elif isinstance(input_data,pd.DataFrame):\n",
    "        data_frame = input_data\n",
    "    index_list = list(data_frame.index.values)\n",
    "    mirrored_pot_list = []\n",
    "    for i in index_list:\n",
    "        pot_array = data_frame.at[i, 'Image Array']\n",
    "        pot_name = 'Pot_%s' %i\n",
    "        \n",
    "        # Makes a list of column values and determines the column in the centre quarter of the\n",
    "        # with the highest value (most likely the centre line) then takes a slice of the image\n",
    "        # array of all the columns up to and including the centre line from the left hand side\n",
    "        # and saves it as a new array. \n",
    "        \n",
    "        column_values = list(pot_array.sum(axis=0))\n",
    "        centre_focus = (int(len(column_values)*3/8))\n",
    "        column_values[:centre_focus] = [0]*centre_focus\n",
    "        column_values[-centre_focus:] = [0]*centre_focus\n",
    "        centre_col = max(column_values)\n",
    "        lhs_pot = pot_array[:,:column_values.index(centre_col)+1]\n",
    "\n",
    "        # Takes a slice of the rightmost x (determined by the centre_slice_pixels parameter) pixels\n",
    "        # of the lhs image (i.e. the centre of the pot),calculates the value of each row of this\n",
    "        # slice, then makes a list of all the indices where the only pixels represented are likely\n",
    "        # to be those of the centre line (based on the centre_line_pixels parameter).\n",
    "        \n",
    "        centre_slice = lhs_pot[:,-centre_slice_pixels:]\n",
    "        row_values = list(centre_slice.sum(axis=1))\n",
    "        bad_row_indices = [i for i, value in enumerate(row_values) if value <= 255*centre_line_pixels]\n",
    "        \n",
    "        # Replaces all white pixels on indices determined as probably only containing the centre line\n",
    "        # with black pixels on the centre slice array, then trims the rightmost x pixels (as above)\n",
    "        # from the lhs array and concatenates it with the centre slice to form a complete lhs image.\n",
    "        \n",
    "        centre_slice[np.array(bad_row_indices), :] = 0\n",
    "        trimmed_lhs_pot = lhs_pot[:,:-centre_slice_pixels]\n",
    "        lhs_pot = np.concatenate((trimmed_lhs_pot, centre_slice),1)\n",
    "        \n",
    "        # Creates a new array by mirroring the left-hand side of the pot on the \n",
    "        # y axis, then concatenates the two arrays into a single output array\n",
    "        \n",
    "        lhs_mirror = np.flip(lhs_pot, 1)\n",
    "        output_pot = np.concatenate((lhs_pot, lhs_mirror),1)\n",
    "        \n",
    "        # This section now makes sure that there aren't any rogue pixels left in the middle of the image.\n",
    "        # These are usually a result of irregularities in the centre line erasion. It does so using\n",
    "        # labelled arrays in a similar way to the initial pot scan. If there are >2 labels (background\n",
    "        # and the body of the pot), the smaller additional labels will be erased, if there are only 2\n",
    "        # labels, the function will continue as there are no irregularities, and if there are < 2 labels,\n",
    "        # something has gone horribly wrong. If lots of correction is needed, consider tweaking the\n",
    "        # function inputs or ensuring that the pot has been properly rotated.  The function then trims the\n",
    "        # image to remove any blank space around the edges, and afterwards the mirrored image is appended\n",
    "        # to the output list\n",
    "        \n",
    "        s = [[255,255,255],\n",
    "             [255,255,255],\n",
    "             [255,255,255]]\n",
    "        labelled_array, num_features = scipy.ndimage.measurements.label(output_pot, structure=s,)\n",
    "        unique_labels, pix_per_label = np.unique(labelled_array, return_counts=True)\n",
    "        if len(unique_labels) == 2:\n",
    "            print (\"%s: No corrections\" % pot_name)\n",
    "        elif len(unique_labels) < 2:\n",
    "            print (\"%s: This shouldn't happen - something's gone wrong!\" % pot_name)\n",
    "        else:\n",
    "            unique_labels = tuple(unique_labels)\n",
    "            pix_per_label = tuple(pix_per_label)\n",
    "            labels_with_pix = list(zip(unique_labels,pix_per_label))\n",
    "            def getKey(item):\n",
    "                return item[1]\n",
    "            ordered_labels_with_pix = sorted(labels_with_pix, key=getKey, reverse=True)\n",
    "            bad_labels = ordered_labels_with_pix[2:]\n",
    "            for (x,y) in bad_labels:\n",
    "                labelled_array[labelled_array == x] = 0\n",
    "            labelled_array[labelled_array > 0] = 255\n",
    "            output_pot = labelled_array\n",
    "            print (\"%s: %s corrections\" % (pot_name, len(unique_labels)-2))\n",
    "        output_pot = output_pot[np.ix_(output_pot.any(1),output_pot.any(0))]\n",
    "        mirrored_pot_list.append(output_pot)\n",
    "    \n",
    "    # After all the images are mirrored, the original image arrays in the data frame\n",
    "    # are replaced with the mirrored versions and the data frame is saved as a .pkl file\n",
    "    \n",
    "    data_frame['Image Array'] = mirrored_pot_list\n",
    "    if output_pkl is True:\n",
    "        if nomen is None:\n",
    "            print (\"NO .pkl PRODUCED - NOMEN REQUIRED FOR .pkl OUTPUT\")\n",
    "        else:\n",
    "            data_frame.to_pickle('mirrored_%s.pkl' % nomen)\n",
    "    return data_frame   \n",
    "\n",
    "\n",
    "###########################\n",
    "# internal_gap_remove_all #\n",
    "###########################\n",
    "# A function to remove any gaps within the cross-section walls of the vessel image. Probably best to apply\n",
    "# this function after horizontal line shave been erased, as otherwise it may interpret the space between\n",
    "# unwanted horizontal lines and the vessel walls as internal space to be deleted. For vessels with handles\n",
    "# or internal subdivisions, ensure that the min_pixel_group_size value is sufficiently small so as not to\n",
    "# misinterpret the spaces between handles and vessel walls as internal spaces to be erased.\n",
    "\n",
    "# Parameters:\n",
    "#         input_pickle : A data frame with the arrays requiring processing stored in the 'Image Array' column\n",
    "# min_pixel_group_size : The minimum size a group of pixels must be to avoid erasure. Pixel groups larger than\n",
    "#                        this value are assumed to be the interior volume of the vessel, the pixels surrounding\n",
    "#                        the outer wall of the vessel, and any other desired 'blank spaces'(subdivisions of the\n",
    "#                        interior volume, the space between handle and ouside wall etc.).\n",
    "\n",
    "\n",
    "\n",
    "#PUT IN A THING TO EXEMPT POTS THAT WE DON'T WANT MESSED WITH\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def internal_gap_removal_all(input_data, min_pixel_group_size = 50, exempt_pots = [], output_pkl=False, nomen=None):\n",
    "    \n",
    "    # Reads the data frame from the input .pkl file and creates an empty list for outputs,\n",
    "    # then iterates through each image array to carry out the rest of the function.\n",
    "    # If Designations are present, these are used for the later print progress\n",
    "    # statements, otherwise generic index based designations are generated and used.\n",
    "    \n",
    "    if type(input_data) == str:\n",
    "        data_frame = pd.read_pickle(input_pickle)\n",
    "    elif isinstance(input_data,pd.DataFrame):\n",
    "        data_frame = input_data\n",
    "    index_list = list(data_frame.index.values)\n",
    "    int_gap_removed_list = []\n",
    "    for i in index_list:\n",
    "        pot_array = data_frame.at[i, 'Image Array']\n",
    "        pot_name = 'Pot_%s' %i\n",
    "        \n",
    "        # Converts the array to an image, adds a 10 pixel black border, inverts the colours,\n",
    "        # then converts it back to an array. Adding the border ensures that all the pixels\n",
    "        # surrounding the outer wall of the pot form one coherent group, thus avoiding the\n",
    "        # undesired erasure of pixel groups bordering the edge of the image. By inverting the\n",
    "        # image, the single group of pixels forming the body of the pot become black, 0 value\n",
    "        # 'background' pixels, while the non-pot pixels, including the unwanted gaps within \n",
    "        # the walls of the vessel as well as the interior and exterior space of the vessel \n",
    "        # become white, 255 value 'foreground' pixels ready to have labelling applied to them.\n",
    "        \n",
    "        pot_array = Image.fromarray(pot_array)\n",
    "        pot_array = pot_array.convert('L')\n",
    "        pot_array = ImageOps.expand(pot_array, border = 10, fill = 'black')\n",
    "        pot_array = ImageOps.invert(pot_array)\n",
    "        pot_array = np.array(pot_array)\n",
    "        \n",
    "        # Labels all the non-zero pixel groups (i.e every pixel group other than the main body\n",
    "        # of the pot) with unique postive integer values. Given there may be several hundred of\n",
    "        # these groups, label 255 is reassigned to be label -1 to avoid its inclusion in the output\n",
    "        \n",
    "        labelled_array, num_features = scipy.ndimage.measurements.label(pot_array)\n",
    "        labelled_array = np.where(labelled_array == 255, -1, labelled_array)\n",
    "        \n",
    "        # Creates a list of tuples containing the integer assigned to each label, and the number of\n",
    "        # pixels that make up each label. An empty list is then created and filled with the integers\n",
    "        # assigned to all non-zero labels deemed sufficiently large as to not be unwanted internal\n",
    "        # space, as determind by the min_pixel_group_size parameter\n",
    "        \n",
    "        unique_labels, pixels_per_label = np.unique(labelled_array, return_counts=True)                                         \n",
    "        unique_labels = tuple(unique_labels)\n",
    "        pixels_per_label = tuple(pixels_per_label)\n",
    "        labels_with_pixels = list(zip(unique_labels,pixels_per_label))\n",
    "        good_labels = []\n",
    "        for (x,y) in labels_with_pixels:\n",
    "            if x != 0 and y >= min_pixel_group_size:\n",
    "                good_labels.append(x)\n",
    "        \n",
    "        # Determines the number of labels that are going to be erased by subtracting the number of\n",
    "        # sufficiently large labels (+ the 0 label) from the total number of unique labels so that\n",
    "        # this value can be printed later on.\n",
    "        \n",
    "        number_of_erased_labels = len(unique_labels) - (len(good_labels)+1)\n",
    "        \n",
    "        # Iterates over the sufficiently large labels and preserves them by turning\n",
    "        # them to 255/white. All other labels (which should just be unwanted space  \n",
    "        # within the vessel walls) are then removed by turning them to 0/black.\n",
    "        \n",
    "        for label in good_labels:\n",
    "            labelled_array = np.where(labelled_array == label, 255, labelled_array)\n",
    "        labelled_array[labelled_array > 255] = 0\n",
    "        labelled_array[labelled_array < 255] = 0\n",
    "        \n",
    "        # The array is converted to an image, inverted again (so that the vessel outline returns to\n",
    "        # being 255/white), and cropped to remove the border added earlier. The image is then converted\n",
    "        # back to an array before being appended to the output list.\n",
    "        \n",
    "        output_array = Image.fromarray(labelled_array)\n",
    "        output_array = output_array.convert('L')\n",
    "        output_array = ImageOps.invert(output_array)\n",
    "        output_array = np.array(output_array)\n",
    "        output_array = output_array[np.ix_(output_array.any(1),output_array.any(0))]\n",
    "        int_gap_removed_list.append(output_array)\n",
    "        \n",
    "        # Print statements detail how many labels were erased in each image. If this value is unexpectedly\n",
    "        # >0 (i.e. if labels are removed from a pot with no spaces within the vessel wall), consider lowering\n",
    "        # the min_pixel_group_size parameter, as it is likely that desired spaces like those between the handle\n",
    "        # and exterior wall of a vessel have been erroneously erased. If >0 labels have been erased, the function\n",
    "        # will print the size in pixels of the largest deleted label. If this value is unexpectedly large,\n",
    "        # it may indicate that a desired space has been erroneously deleted. This value can also be used to\n",
    "        # tighten the min_pixel_group_size parameter for repeated uses of the function.\n",
    "        \n",
    "        print (\"%s: %s labels removed\" %(pot_name, number_of_erased_labels))\n",
    "        if number_of_erased_labels > 0:\n",
    "            bad_pixel_size_list = []\n",
    "            for (x,y) in labels_with_pixels:\n",
    "                if x not in good_labels and x != 0:\n",
    "                    bad_pixel_size_list.append(y)\n",
    "            bad_pixel_size_list = sorted(bad_pixel_size_list, reverse = True)\n",
    "            print ('Largest deletion: %s pixels' % bad_pixel_size_list[0])\n",
    "    \n",
    "    # After all the arrays are processed, the original image arrays in the data frame\n",
    "    # are replaced with the processed versions and the data frame is saved as a .pkl file\n",
    "    \n",
    "    data_frame['Image Array'] = int_gap_removed_list\n",
    "    if output_pkl is True:\n",
    "        if nomen is None:\n",
    "            print (\"NO .pkl PRODUCED - NOMEN REQUIRED FOR .pkl OUTPUT\")\n",
    "        else:\n",
    "            data_frame.to_pickle('intgapped_%s.pkl' % nomen)\n",
    "    return data_frame       \n",
    "\n",
    "\n",
    "##################\n",
    "# area_labelling #\n",
    "##################\n",
    "# A function to label fully processed image_arrays so that their measurements and shape characteristics can be\n",
    "# determined. The output labels are as follows:\n",
    "# 0 : The body of the vessel\n",
    "# 1 : The interior of the vessel\n",
    "# 2 : The exterior of the vessel\n",
    "# 3 : If present in the image, any additional spaces that cannot be certainly identified as interior or exterior.\n",
    "#     These areas are typically enclosed areas between handles and vessel exterior walls, or errors resulting\n",
    "#     from the survival of unidentified interior lines or unidentified spaces within the vessel walls\n",
    "# This array is saved to the pickle file under a new 'Labelled Array' column. The function also produces a version\n",
    "# of this array with the values multiplied by 85 and saves it to the pickle file under a new 'Labelled Display Array'\n",
    "# column. The arrays in this column can be converted into human-readable greyscale .pngs to check for labelling errors.\n",
    "# The colours and pixel values of the display .pngs are as follows:\n",
    "#     0 (body) : Black (0)\n",
    "# 1 (interior) : Dark Grey (85)\n",
    "# 2 (exterior) : Light Grey (170)\n",
    "#    3 (other) : White (255)\n",
    "\n",
    "# Parameters:\n",
    "# input_data : A data frame with the arrays to be labelled stored in the 'Image Array' column\n",
    "# hatched_interior: A True/False statement. If True, it assumes the scanned vessel does not have a fill;ed in interior (ie is outline only or hatched interior)\n",
    "#                   and then assumes that any interior gaps found need to be filled in. !REQUIRES CAREFUL PREPROCESSING!\n",
    "# est_int_height: The estimated height of the interior. usually 1/3 is fine (i.e. a third of the way down from the top), but for some vessel types like lids, a lower value may be needed\n",
    "\n",
    "def area_labelling_all(input_data, hatched_interior=False, est_int_height=(1/3), output_pkl=False, nomen=None):\n",
    "    \n",
    "    # Reads the data frame from the input .pkl file and creates empty lists for outputs\n",
    "    # then iterates through each image array to carry out the rest of the function.\n",
    "    # If Designations are present, these are used for the later print progress\n",
    "    # statements, otherwise generic index based designations are generated and used.\n",
    "    #\n",
    "    # Now with a setting do deal with hatched vessels - need to make sure in preprocessing that there are no actual gaps\n",
    "    \n",
    "    if type(input_data) == str:\n",
    "        data_frame = pd.read_pickle(input_pickle)\n",
    "    elif isinstance(input_data,pd.DataFrame):\n",
    "        data_frame = input_data\n",
    "    index_list = list(data_frame.index.values)\n",
    "    labelled_pot_list = []\n",
    "    for i in index_list:\n",
    "        pot_array = data_frame.at[i, 'Image Array']\n",
    "        pot_name = 'Pot_%s' %i\n",
    "        \n",
    "        # Converts the array to an image and inverts it so that the later labelling picks up\n",
    "        # groups of non vessel body pixels, then converts it back to an array.\n",
    "        \n",
    "        pot_array = Image.fromarray(pot_array)\n",
    "        pot_array = pot_array.convert('L')\n",
    "        pot_array = ImageOps.invert(pot_array)\n",
    "        pot_array = np.array(pot_array)\n",
    "        \n",
    "        # Labels the unique non-zero pixel groups of the array with unique positive integers\n",
    "        # then determines the index of a pixel approximately 2/3 of the way up the centre of\n",
    "        # the pot. It is assumed that this label represents the main interior section of the\n",
    "        # vessel (for this reason lids, or other vessels with open bottoms and closed tops\n",
    "        # are best labelled while upside down, at least until I can figure out a better way\n",
    "        # of doing this) so the values for this label are all turned to -1 in a new output_array.\n",
    "        # If the selected pixel forms part of the vessel body, pixels in higher rows of the\n",
    "        # same column are tested until a non-body-pixel is discovered\n",
    "        #\n",
    "        # Now uses a variable rather than assuming a 2/3 of the way up height (though thats still the default)\n",
    "\n",
    "        s = [[255,255,255],\n",
    "             [255,255,255],\n",
    "             [255,255,255]]\n",
    "        labelled_array, num_features = scipy.ndimage.measurements.label(pot_array, structure=s)\n",
    "        (row_number,col_number) = np.shape(pot_array)\n",
    "        max_row_index = row_number - 1\n",
    "        max_col_index = col_number - 1\n",
    "        prob_int_index = (int(max_row_index*(est_int_height)),int(max_col_index/2))\n",
    "        \n",
    "        if labelled_array[prob_int_index] != 0:\n",
    "            interior_label = labelled_array[prob_int_index]\n",
    "            output_array = np.where(labelled_array == interior_label, -1, labelled_array)\n",
    "        else:\n",
    "            counter = 1\n",
    "            while labelled_array[prob_int_index] == 0 and counter < max_row_index:\n",
    "                prob_int_index = (int((max_row_index*(1/3))-counter),int(max_col_index/2))\n",
    "                counter += 1\n",
    "                print (counter)\n",
    "            interior_label = labelled_array[prob_int_index]\n",
    "            output_array = np.where(labelled_array == interior_label, -1, labelled_array)\n",
    "        \n",
    "        # Creates a list containing all the unique labels on the output array, then iterates over all\n",
    "        # the values >0 so as to leave out the vessel interior (-1) and vessel wall (0). For each value\n",
    "        # it generates a list of all the indices where that value is located, then iterates over this list\n",
    "        # to see if any of the indices form part of the outside edge of the array. If any do, the label is\n",
    "        # determined to be totally outside of the vessel, its values are turned to -2, and the index list\n",
    "        # for that label stops being iterated over. Once this process is complete, any remaining positive\n",
    "        # labels must be neither the main interior of the vessel, or the exterior, (these are likely to be\n",
    "        # spaces such as the gap between a vessel wall and a handle), and their values are turned to -3.\n",
    "        \n",
    "        unique_labels, pixels_per_label = np.unique(output_array, return_counts=True)\n",
    "        for label in unique_labels:\n",
    "            if label > 0:\n",
    "                (row_index,col_index) = np.where(output_array==label)\n",
    "                row_index = tuple(row_index)\n",
    "                col_index = tuple(col_index)\n",
    "                rows_and_cols_indices = list(zip(row_index,col_index))\n",
    "                for (row,col) in rows_and_cols_indices:\n",
    "                    if row == 0 or row == max_row_index or col == 0 or col == max_col_index:\n",
    "                        output_array = np.where(output_array == label, -2, output_array)\n",
    "                        break\n",
    "        output_array = np.where(output_array > 0, -3, output_array)\n",
    "        \n",
    "        # If the vessels being labelled have a crosshatched rather than fully inked in interior, and the\n",
    "        # hatched interior value has been set to True, any internal space is assumed to be body, and changed\n",
    "        # accordingly\n",
    "        \n",
    "        if hatched_interior == True:\n",
    "            output_array = np.where(output_array == -3, 0, output_array)\n",
    "        \n",
    "        \n",
    "        # The output array is multiplied by -1 to make all 4 labelled groups positive, and the output\n",
    "        # arrays are appended to an output list.\n",
    "        \n",
    "        output_array = output_array*-1\n",
    "        labelled_pot_list.append(output_array)\n",
    "        print ('%s labelled' % pot_name)\n",
    "        \n",
    "    # The labelled arrays are added to the data frame as new columns, the old image arrays are deleted\n",
    "    # to save space, and the dataframe is saved as a new pickle file.\n",
    "    \n",
    "    data_frame['Labelled Array'] = labelled_pot_list\n",
    "    data_frame = data_frame.drop('Image Array', axis=1)\n",
    "    if output_pkl is True:\n",
    "        if nomen is None:\n",
    "            print (\"NO .pkl PRODUCED - NOMEN REQUIRED FOR .pkl OUTPUT\")\n",
    "        else:\n",
    "            data_frame.to_pickle('labelled_%s.pkl' % nomen)\n",
    "    return data_frame \n",
    "\n",
    "\n",
    "    \n",
    "#########################\n",
    "# output_display_arrays #\n",
    "#########################\n",
    "\n",
    "# A function to output display versions of the labelled arrays in a .pkl file as .pngs.\n",
    "# Originally these arrays were saved on the .pkl, but to save space these are now only \n",
    "# produced when required.\n",
    "#\n",
    "# Parameters:\n",
    "# input_pickle : A data frame from which to take the desired image arrays\n",
    "\n",
    "\n",
    "def output_display_arrays(input_data, nomen=None):\n",
    "    \n",
    "    # Reads the data from the .pkl file and creates a folder to contain the .pngs\n",
    "    \n",
    "    if type(input_data) == str:\n",
    "        data_frame = pd.read_pickle(input_data)\n",
    "    elif isinstance(input_data,pd.DataFrame):\n",
    "        data_frame = input_data\n",
    "    folder_name = nomen+'-Display_Arrays'\n",
    "    os.mkdir(folder_name)\n",
    "    os.chdir(folder_name)\n",
    "    \n",
    "    # Iterates over every array on the dataframe, multiplies the array by 85 to\n",
    "    # make the labells more visually distinct, then outputs them as .png files.\n",
    "    # If the dataframe contains a Designation column, the .png filenames are derived\n",
    "    # from this, with the index added to avoid duplications of pots erroneously given the same designation, otherwise they are derived from the index values.\n",
    "    \n",
    "    index_list = list(data_frame.index.values)\n",
    "    for i in index_list:\n",
    "        pot_array = data_frame.at[i, 'Labelled Array']\n",
    "        display_array = pot_array*85\n",
    "        output_image = Image.fromarray(display_array)\n",
    "        output_image = output_image.convert('L')\n",
    "        if 'Designation' in data_frame.columns:\n",
    "            pot_name = data_frame.at[i, 'Designation']\n",
    "            output_image.save('%s.png' %(str(pot_name)+\"_at_index_\"+str(i)))\n",
    "        else:\n",
    "            output_image.save('pot_at_index_%s.png' %str(i).zfill(5))\n",
    "    os.chdir(\"..\")   \n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def the_lot_2(input_dir_list, get_measures=False, horiz_remove=False):\n",
    "    \n",
    "    for filename in input_dir_list:\n",
    "        nomen = Path(filename).stem\n",
    "        print (nomen)\n",
    "        print (\"SCANNING IMAGE\")\n",
    "        scan_output_df = pot_scan_to_pkl(input_page=filename, threshold=None, diagonal_pixel_groups=True, viable_pot_size=6000, output_pkl=False, nomen=nomen)\n",
    "        print (\"AUTOROTATING\")\n",
    "        rotate_output_df = new_autorotate_all(input_data=scan_output_df, degree_range=2,degree_increment=1/8, ignore_horizontals=False, output_pkl=False, nomen=nomen)\n",
    "        print (\"MIRRORING\")\n",
    "        mirrored_output_df = mirror_and_trim_centre_all(input_data=rotate_output_df, centre_slice_pixels=10, centre_line_pixels=6, output_pkl=False, nomen=nomen)\n",
    "        print (\"GAP REMOVAL\")\n",
    "        intgapped_output_df = internal_gap_removal_all(input_data=mirrored_output_df, output_pkl=False, nomen=nomen)\n",
    "        if horiz_remove is True:\n",
    "            #print (\"HORIZONTAL LINE REMOVAL\")\n",
    "            #horiz_output_df = ####\n",
    "            #print (\"LABELLING\")\n",
    "            #labelled_output_df = ####\n",
    "            print (\"JUST DON'T DO IT\")\n",
    "        else:\n",
    "            print (\"LABELLING\")\n",
    "            labelled_output_df = area_labelling_all(input_data=intgapped_output_df, hatched_interior=True, est_int_height=1/3,output_pkl=True, nomen=nomen)\n",
    "        print (\"PRODUCING PNG OUTPUT\")\n",
    "        output_display_arrays(input_data=labelled_output_df, nomen=nomen)\n",
    "        print()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def add_designations(input_pickle, designation_list=[], concat_pickle=None, ignore_index=True):\n",
    "    \n",
    "    data_frame = pd.read_pickle(input_pickle)\n",
    "    data_frame['Designation'] = designation_list\n",
    "    \n",
    "    print (data_frame)\n",
    "    \n",
    "    \n",
    "    if concat_pickle != None:\n",
    "        concat_data_frame = pd.read_pickle(concat_pickle)\n",
    "        output_pickle = pd.concat([concat_data_frame,data_frame], ignore_index=ignore_index)\n",
    "        print (output_pickle)\n",
    "        output_pickle.to_pickle('Concat_%s.pkl' % concat_pickle[:-4])\n",
    "    \n",
    "    #saves bonus data_frame anyway\n",
    "    \n",
    "    data_frame.to_pickle('Designated_%s.pkl' % input_pickle[9:-4])\n",
    "    \n",
    "    #pkl_to_png('Concat_%s.pkl' % concat_pickle[:-4], output_column = 'Labelled Display Array', use_designations=True)\n",
    "    if concat_pickle != None:\n",
    "        output_display_arrays('Concat_%s.pkl' % concat_pickle[:-4])\n",
    "    elif concat_pickle == None:\n",
    "        output_display_arrays(data_frame, nomen=str(input_pickle[9:-4]))\n",
    "        \n",
    "        \n",
    "\n",
    "################\n",
    "# get_measures #\n",
    "################\n",
    "# A function to derive a series of measures from a pickle file containing a labelled array\n",
    "\n",
    "# Parameters:\n",
    "# input_pickle : A data frame containing labelled arrays from which measures can be derived stored in the 'Labelled Array' column\n",
    "#  output_name : A string to save the final output as. If undefined, the pickle is saved as 'FINAL_(input_pickle).pkl'\n",
    "\n",
    "def get_measures(input_pickle, output_name=None):\n",
    "    \n",
    "    # Opens the data frame and creates an index list for later iteration, as well \n",
    "    # as empty lists to fill with different arrays to obtain different measures\n",
    "    \n",
    "    data_frame = pd.read_pickle(input_pickle)\n",
    "    index_list = list(data_frame.index.values)\n",
    "    \n",
    "    body_array_list = []\n",
    "    interior_array_list = []\n",
    "    sil_array_list = []\n",
    "    \n",
    "    print (\"PKL FILE UNPACKED\")\n",
    "    print ()\n",
    "    \n",
    "    # Iterates over each entry in the data_frame, creating three arrays from the initial labelled\n",
    "    # array, which are appended to a list and then saved as new columns on the data frame:\n",
    "    #       Body Array : containing only pixels that form the body of the vessel\n",
    "    #   Interior Array : containing only pixels that form the largest interior space in the vessel\n",
    "    # Silhouette Array : containing both the pixels of the vessel body and primary interior space\n",
    "    \n",
    "    for i in index_list:\n",
    "        body_array = data_frame.at[i, 'Labelled Array']\n",
    "        body_array = np.where(body_array == 0, 1, 0)\n",
    "        body_array_list.append(body_array)\n",
    "        \n",
    "        interior_array = data_frame.at[i, 'Labelled Array']\n",
    "        interior_array = np.where(interior_array == 1, 1, 0)\n",
    "        interior_array_list.append(interior_array)\n",
    "        \n",
    "        sil_array = data_frame.at[i, 'Labelled Array']\n",
    "        sil_array = np.where(sil_array == 0, 1, sil_array)\n",
    "        sil_array = np.where(sil_array == 1, 1, 0)\n",
    "        sil_array_list.append(sil_array)\n",
    "        \n",
    "        print(\"Secondary Array Gen: %s of %s\" % (i+1,len(index_list)))\n",
    "        \n",
    "    data_frame['Body Array'] = body_array_list\n",
    "    data_frame['Interior Array'] = interior_array_list\n",
    "    data_frame['Silhouette Array'] = sil_array_list\n",
    "    \n",
    "    print ()\n",
    "    print (\"ALL SECONDARY ARRAYS GENERATED\")\n",
    "    print ()\n",
    "    \n",
    "    # Creates a series of lists to fill with values derived from the above \n",
    "    # created arrays, then iterates over the data frame to obtain these values.\n",
    "    \n",
    "    body_height_list = []\n",
    "    body_width_list = []\n",
    "    body_area_list = []\n",
    "    body_centroid_list = []\n",
    "    body_perimeter_list = []\n",
    "    \n",
    "    interior_height_list = []\n",
    "    interior_width_list = []\n",
    "    interior_area_list = []\n",
    "    interior_centroid_list_r_int = []\n",
    "    interior_centroid_list_r_bod = []\n",
    "    interior_perimeter_list = []\n",
    "    \n",
    "    sil_area_list = []\n",
    "    sil_centroid_list = []\n",
    "    sil_perimeter_list = []\n",
    "    \n",
    "    for i in index_list:\n",
    "        \n",
    "        # The body array is read off the data frame, and the array is trimmed to the tightest possible\n",
    "        # rectangle around the upright pot. As a result, the height and width of the pot body (in pixels)\n",
    "        # == the height and width of the array, values that can be easily obtained using the inbuilt\n",
    "        # numpy.shape function. The area of the pot body (in pixels) can be obtained by counting the\n",
    "        # number of nonzero pixels. The coordinates of the centroid can be calculated using a scipy\n",
    "        # function. Because the pot arrays have been horixontally mirrored around the centre, the\n",
    "        # horizontal centroid should always be at the vertical centre line, and is not really worth recording.\n",
    "        \n",
    "        body_array = data_frame.at[i, 'Body Array']\n",
    "        body_array = body_array[np.ix_(body_array.any(1),body_array.any(0))]\n",
    "        (body_height, body_width) = body_array.shape\n",
    "        body_area = np.count_nonzero(body_array)\n",
    "        (body_v_centroid, body_h_centroid) = scipy.ndimage.measurements.center_of_mass(body_array)\n",
    "        \n",
    "        # Caluclating the perimeter is slightly more complicated: The array is padded with a border of zero-value\n",
    "        # pixels, a perimeter counter is set up, starting at 0, and then the indicies of non-zero pixels are recorded\n",
    "        # in a list. This list is then iterated over and for each zero-value pixel non-diagonally adjacent to a body\n",
    "        # pixel, the perimeter count is increased by one\n",
    "        \n",
    "        padded_body_array = np.pad(body_array, pad_width=1, mode='constant')\n",
    "        body_perimeter = 0\n",
    "        (body_rows,body_cols) = np.nonzero(padded_body_array)\n",
    "        body_rows = tuple(body_rows)\n",
    "        body_cols = tuple(body_cols)\n",
    "        body_indices = list(zip(body_rows,body_cols))\n",
    "        for (x,y) in body_indices:\n",
    "            if padded_body_array[x+1,y] == 0:\n",
    "                body_perimeter += 1\n",
    "            if padded_body_array[x-1,y] == 0:\n",
    "                body_perimeter += 1\n",
    "            if padded_body_array[x,y+1] == 0:\n",
    "                body_perimeter += 1\n",
    "            if padded_body_array[x,y-1] == 0:\n",
    "                body_perimeter += 1\n",
    "        \n",
    "        # The above determined values are then appended to lists\n",
    "        \n",
    "        body_height_list.append(body_height)\n",
    "        body_width_list.append(body_width)\n",
    "        body_area_list.append(body_area)\n",
    "        body_centroid_list.append(body_v_centroid)\n",
    "        body_perimeter_list.append(body_perimeter) \n",
    "        \n",
    "        # Interior measures are calculated in a largely similar fashion. The only difference is that the vertical centroid\n",
    "        # is calculated twice. First it is calculated in the context of the height of the whole vessel before the array is\n",
    "        # cropped to just a rectangle around the interior pixels. Then it is calculated again after the image has been cropped\n",
    "        # in the context of the height of the interior only. While both values represent the same point (the interior vertical\n",
    "        # centroid), the reindexing that occurs following cropping means that two different centroid values are necessary for\n",
    "        # comparisson with the height of the whole vessel (inlcuding base/feet) and that of the interior alone\n",
    "        \n",
    "        interior_array = data_frame.at[i, 'Interior Array']\n",
    "        \n",
    "        (interior_v_centroid_r_bod, interior_h_centroid_r_bod) = scipy.ndimage.measurements.center_of_mass(interior_array)\n",
    "        \n",
    "        trimmed_interior_array = interior_array[np.ix_(interior_array.any(1),interior_array.any(0))]\n",
    "        \n",
    "        (interior_height, interior_width) = trimmed_interior_array.shape\n",
    "        interior_area = np.count_nonzero(trimmed_interior_array)\n",
    "        (interior_v_centroid_r_int, interior_h_centroid_r_int) = scipy.ndimage.measurements.center_of_mass(trimmed_interior_array)\n",
    "        \n",
    "        padded_interior_array = np.pad(trimmed_interior_array, pad_width=1, mode='constant')\n",
    "        interior_perimeter = 0\n",
    "        (interior_rows,interior_cols) = np.nonzero(padded_interior_array)\n",
    "        interior_rows = tuple(interior_rows)\n",
    "        interior_cols = tuple(interior_cols)\n",
    "        interior_indices = list(zip(interior_rows,interior_cols))\n",
    "        for (x,y) in interior_indices:\n",
    "            if padded_interior_array[x+1,y] == 0:\n",
    "                interior_perimeter += 1\n",
    "            if padded_interior_array[x-1,y] == 0:\n",
    "                interior_perimeter += 1\n",
    "            if padded_interior_array[x,y+1] == 0:\n",
    "                interior_perimeter += 1\n",
    "            if padded_interior_array[x,y-1] == 0:\n",
    "                interior_perimeter += 1        \n",
    "        \n",
    "        interior_height_list.append(interior_height)\n",
    "        interior_width_list.append(interior_width)\n",
    "        interior_area_list.append(interior_area)\n",
    "        interior_centroid_list_r_bod.append(interior_v_centroid_r_bod)\n",
    "        interior_centroid_list_r_int.append(interior_v_centroid_r_int)\n",
    "        interior_perimeter_list.append(interior_perimeter)\n",
    "        \n",
    "        # The silhouette measures are obtained in a similar fashion to the body measures. Height\n",
    "        # and width measures are not necessary as these will be the same as body height and width\n",
    "        \n",
    "        sil_array = data_frame.at[i, 'Silhouette Array']\n",
    "        sil_array = sil_array[np.ix_(sil_array.any(1),sil_array.any(0))]\n",
    "        sil_area = np.count_nonzero(sil_array)\n",
    "        (sil_v_centroid, sil_h_centroid) = scipy.ndimage.measurements.center_of_mass(sil_array)\n",
    "        \n",
    "        padded_sil_array = np.pad(sil_array, pad_width=1, mode='constant')\n",
    "        sil_perimeter = 0\n",
    "        (sil_rows, sil_cols) = np.nonzero(padded_sil_array)\n",
    "        sil_rows = tuple(sil_rows)\n",
    "        sil_cols = tuple(sil_cols)\n",
    "        sil_indices = list(zip(sil_rows,sil_cols))\n",
    "        for (x,y) in sil_indices:\n",
    "            if padded_sil_array[x+1,y] == 0:\n",
    "                sil_perimeter += 1\n",
    "            if padded_sil_array[x-1,y] == 0:\n",
    "                sil_perimeter += 1\n",
    "            if padded_sil_array[x,y+1] == 0:\n",
    "                sil_perimeter += 1\n",
    "            if padded_sil_array[x,y-1] == 0:\n",
    "                sil_perimeter += 1                    \n",
    "        \n",
    "        sil_area_list.append(sil_area)\n",
    "        sil_perimeter_list.append(sil_perimeter)\n",
    "        sil_centroid_list.append(sil_v_centroid)\n",
    "        \n",
    "        print(\"Initial Measuring: %s of %s\" % (i+1,len(index_list)))\n",
    "        \n",
    "    # The lists complied above are then added to the dataframe\n",
    "    \n",
    "    data_frame['Body Height'] = body_height_list\n",
    "    data_frame['Body Width'] = body_width_list\n",
    "    data_frame['Body Area'] = body_area_list\n",
    "    data_frame['Body Centroid'] = body_centroid_list\n",
    "    data_frame['Body Perimeter'] = body_perimeter_list\n",
    "    \n",
    "    data_frame['Interior Height'] = interior_height_list\n",
    "    data_frame['Interior Width'] = interior_width_list\n",
    "    data_frame['Interior Area'] = interior_area_list\n",
    "    data_frame['Interior Centroid Relating To Body Height'] = interior_centroid_list_r_bod\n",
    "    data_frame['Interior Centroid Relating To Interior Height'] = interior_centroid_list_r_int\n",
    "    data_frame['Interior Perimeter'] = interior_perimeter_list\n",
    "    \n",
    "    data_frame['Silhouette Centroid'] = sil_centroid_list\n",
    "    data_frame['Silhouette Area'] = sil_area_list\n",
    "    data_frame['Silhouette Perimeter'] = sil_perimeter_list\n",
    "    \n",
    "    print ()\n",
    "    print (\"ALL INITAL MEASURES TAKEN\")\n",
    "    print ()\n",
    "    \n",
    "    # The below measures are then derived from the values calculated above,\n",
    "    # and added to the data frame as new columns. The data frame is then saved\n",
    "    # as a pickle file under a new name based on the name of the input pickle \n",
    "    \n",
    "    body_width_over_height_list = []\n",
    "    body_centroid_over_height_list = []\n",
    "    body_rectangularity_list = []\n",
    "    body_circularity_list = []\n",
    "    \n",
    "    interior_width_over_height_list = []\n",
    "    interior_centroid_over_interior_height_list = []\n",
    "    interior_centroid_over_body_height_list = []\n",
    "    interior_rectangularity_list = []\n",
    "    interior_circularity_list = []\n",
    "    \n",
    "    sil_centroid_over_height_list = []\n",
    "    sil_rectangularity_list = []\n",
    "    sil_circularity_list = []\n",
    "\n",
    "    for i in index_list:\n",
    "        \n",
    "        body_width = data_frame.at[i, 'Body Width']\n",
    "        body_height = data_frame.at[i, 'Body Height']\n",
    "        body_width_over_height = body_width/body_height\n",
    "        body_width_over_height_list.append(body_width_over_height)\n",
    "        \n",
    "        body_centroid = data_frame.at[i, 'Body Centroid']\n",
    "        body_centroid_over_height = body_centroid/body_height\n",
    "        body_centroid_over_height_list.append(body_centroid_over_height)\n",
    "        \n",
    "        body_area = data_frame.at[i, 'Body Area']\n",
    "        body_rectangularity = body_area/(body_height*body_width)\n",
    "        body_rectangularity_list.append(body_rectangularity)\n",
    "        \n",
    "        body_perimeter = data_frame.at[i, 'Body Perimeter']\n",
    "        body_circularity = (4*math.pi*body_area)/(body_perimeter*body_perimeter)\n",
    "        body_circularity_list.append(body_circularity)\n",
    "        \n",
    "        interior_width = data_frame.at[i, 'Interior Width']\n",
    "        interior_height = data_frame.at[i, 'Interior Height']\n",
    "        interior_width_over_height = interior_width/interior_height\n",
    "        interior_width_over_height_list.append(interior_width_over_height)\n",
    "        \n",
    "        interior_centroid_r_int = data_frame.at[i, 'Interior Centroid Relating To Interior Height']\n",
    "        interior_centroid_over_interior_height = interior_centroid_r_int/interior_height\n",
    "        interior_centroid_over_interior_height_list.append(interior_centroid_over_interior_height)\n",
    "        \n",
    "        interior_centroid_r_bod = data_frame.at[i, 'Interior Centroid Relating To Body Height']\n",
    "        interior_centroid_over_body_height = interior_centroid_r_bod/body_height\n",
    "        interior_centroid_over_body_height_list.append(interior_centroid_over_body_height)\n",
    "        \n",
    "        interior_area = data_frame.at[i, 'Interior Area']\n",
    "        interior_rectangularity = interior_area/(interior_height*interior_width)\n",
    "        interior_rectangularity_list.append(interior_rectangularity)\n",
    "\n",
    "        interior_perimeter = data_frame.at[i, 'Interior Perimeter']\n",
    "        interior_circularity = (4*math.pi*interior_area)/(interior_perimeter*interior_perimeter)\n",
    "        interior_circularity_list.append(interior_circularity)\n",
    "        \n",
    "        sil_centroid = data_frame.at[i, 'Silhouette Centroid']\n",
    "        sil_centroid_over_height = sil_centroid/body_height\n",
    "        sil_centroid_over_height_list.append(sil_centroid_over_height)\n",
    "        \n",
    "        sil_area = data_frame.at[i, 'Silhouette Area']\n",
    "        sil_rectangularity = sil_area/(body_height*body_width)\n",
    "        sil_rectangularity_list.append(sil_rectangularity)\n",
    "        \n",
    "        sil_perimeter = data_frame.at[i, 'Silhouette Perimeter']\n",
    "        sil_circularity = (4*math.pi*sil_area)/(sil_perimeter*sil_perimeter)\n",
    "        sil_circularity_list.append(sil_circularity)\n",
    "        \n",
    "        print(\"Calculating Measures: %s of %s\" % (i+1,len(index_list)))\n",
    "        \n",
    "    data_frame['Body Width/Height'] = body_width_over_height_list\n",
    "    data_frame['Body Centroid/Height'] = body_centroid_over_height_list\n",
    "    data_frame['Body Rectangularity'] = body_rectangularity_list\n",
    "    data_frame['Body Circularity'] = body_circularity_list\n",
    "\n",
    "    data_frame['Interior Width/Height'] = interior_width_over_height_list\n",
    "    data_frame['Interior Centroid/Interior Height'] = interior_centroid_over_interior_height_list\n",
    "    data_frame['Interior Centroid/Body Height'] = interior_centroid_over_body_height_list\n",
    "    data_frame['Interior Rectangularity'] = interior_rectangularity_list\n",
    "    data_frame['Interior Circularity'] = interior_circularity_list   \n",
    "    \n",
    "    data_frame['Silhouette Centroid/Height'] = sil_centroid_over_height_list\n",
    "    data_frame['Silhouette Rectangularity'] = sil_rectangularity_list\n",
    "    data_frame['Silhouette Circularity'] = sil_circularity_list\n",
    "    \n",
    "    print (\"ALL CALCULATED MEASURES DERIVED\")\n",
    "    \n",
    "    # Drops the created image arrays to save space\n",
    "    \n",
    "    data_frame = data_frame.drop(['Body Array', 'Interior Array', 'Silhouette Array'], axis=1)\n",
    "    print (data_frame)\n",
    "    \n",
    "    if output_name == None:\n",
    "        data_frame.to_pickle('FINAL_%s' % (input_pickle))\n",
    "    else:\n",
    "        if str(output_name[-4:]) != '.pkl':\n",
    "            output_name += '.pkl'\n",
    "        data_frame.to_pickle(output_name)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
